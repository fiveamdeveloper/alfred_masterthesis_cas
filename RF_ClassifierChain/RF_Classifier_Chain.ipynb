{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Implementierung mit ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = f'./model_files'\n",
    "\n",
    "# Laden der Classifier Chain\n",
    "with open(f'{model_directory}/classifier_chain-v5g.pkl', 'rb') as chain_file:\n",
    "    classifier_chain = pickle.load(chain_file)\n",
    "\n",
    "# Laden der Encoder und des TfidfVectorizer\n",
    "with open(f'{model_directory}/select_encoder-v5g.pkl', 'rb') as file:\n",
    "    select_encoder = pickle.load(file)\n",
    "\n",
    "with open(f'{model_directory}/required_encoder-v5g.pkl', 'rb') as file:\n",
    "    required_encoder = pickle.load(file)\n",
    "\n",
    "with open(f'{model_directory}/expand_encoder-v5g.pkl', 'rb') as file:\n",
    "    expand_encoder = pickle.load(file)\n",
    "\n",
    "with open(f'{model_directory}/expand_select_encoder-v5g.pkl', 'rb') as file:\n",
    "    expand_select_encoder = pickle.load(file)\n",
    "\n",
    "with open(f'{model_directory}/endpoint_encoder-v5g.pkl', 'rb') as file:\n",
    "    endpoint_encoder = pickle.load(file)\n",
    "\n",
    "with open(f'{model_directory}/method_encoder-v5g.pkl', 'rb') as file:\n",
    "    method_encoder = pickle.load(file)\n",
    "\n",
    "with open(f'{model_directory}/presentation_encoder-v5g.pkl', 'rb') as file:\n",
    "    presentation_encoder = pickle.load(file)\n",
    "\n",
    "with open(f'{model_directory}/alfred_encoder-v5g.pkl', 'rb') as file:\n",
    "    alfred_encoder = pickle.load(file)\n",
    "\n",
    "with open(f'{model_directory}/filter_encoder-v5g.pkl', 'rb') as file:\n",
    "    filter_encoder = pickle.load(file)\n",
    "\n",
    "with open(f'{model_directory}/tfidf_vectorizer-v5g.pkl', 'rb') as vectorizer_file:\n",
    "    vectorizer = pickle.load(vectorizer_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorverarbeitung des Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Bereinigung des Textes\n",
    "def clean_text(text):\n",
    "     # Entfernen von Sonderzeichen und Ziffern\n",
    "     if pd.isna(text):  # Überprüfen auf NaN-Werte\n",
    "          return text\n",
    "     text = re.sub(r'[^A-Za-zäöüßÄÖÜ\\s]', '', text)\n",
    "\n",
    "     # Optional: Umwandlung in Kleinbuchstaben\n",
    "     text = text.lower()\n",
    "\n",
    "     # Entfernen unnötiger Leerzeichen\n",
    "     text = text.strip()\n",
    "\n",
    "     return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Variable ```USER_PROMPT``` kann die Klassifikation getestet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"Welche Komponenten werden im Auftrag 4711 benötigt?\" # Mit diesem Prompt kann die Klassifikation getestet werden.\n",
    "PRE_USER_PROMPT = clean_text(USER_PROMPT) # Prompt um Sonderzeichen bereinigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durchführung der Vorhersage mit der ClassifierChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vektorisierung des Textes für eine verbesserte Berechnung sowie Durchführung der Vorhersage, ausgehend von dem vorverarbeiteten Prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vektorisierung des Texts\n",
    "prompt_vector = vectorizer.transform([PRE_USER_PROMPT])\n",
    "\n",
    "# Vorhersage mit der Classifier Chain\n",
    "user_prompt_prediction = classifier_chain.predict(prompt_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Nachfolgenden Abschnitt wird die Vorhersage in Klartext dekodiert. Die Reihenfolge der von-bis Werte ist hier sehr wichtig. Die Klassifikationskette, mit der trainiert wurde, gibt diese vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Prediction: API_PRODUCTION_ORDER_2_SRV/A_ProductionOrderComponent\n",
      "Method Prediction: GET\n",
      "Presentation Prediction: blank\n",
      "Select Prediction: [('ManufacturingOrder',)]\n",
      "Required Prediction: [('ManufacturingOrder',)]\n",
      "Expand Prediction: [('to_ProductionOrderComponent',)]\n",
      "Expand Select Prediction: [('BaseUnit', 'ManufacturingOrderOperation', 'Material', 'ProductionPlant', 'RequiredQuantity')]\n",
      "Filter Prediction: [()]\n",
      "Alfred Prediction: [()]\n"
     ]
    }
   ],
   "source": [
    "# Umwandeln der Vorhersagen in Integer-Werte für die Dekodierung\n",
    "predicted_endpoint_indices = user_prompt_prediction[:, 0].astype(int).ravel()\n",
    "predicted_method_indices = user_prompt_prediction[:, 1].astype(int).ravel()\n",
    "predicted_presentation_indices = user_prompt_prediction[:, 2].astype(int).ravel()\n",
    "\n",
    "# Dekodieren der Single-Label-Vorhersagen\n",
    "decoded_prediction_endpoint = endpoint_encoder.inverse_transform(predicted_endpoint_indices)\n",
    "decoded_prediction_method = method_encoder.inverse_transform(predicted_method_indices)\n",
    "decoded_prediction_presentation = presentation_encoder.inverse_transform(predicted_presentation_indices)\n",
    "\n",
    "# Multi-Label-Vorhersagen dekodieren\n",
    "decoded_prediction_select = select_encoder.inverse_transform(user_prompt_prediction[:, :len(select_encoder.classes_)])\n",
    "decoded_prediction_required = required_encoder.inverse_transform(user_prompt_prediction[:, len(select_encoder.classes_):len(select_encoder.classes_)+len(required_encoder.classes_)])\n",
    "decoded_prediction_expand = expand_encoder.inverse_transform(user_prompt_prediction[:, len(select_encoder.classes_)+len(required_encoder.classes_):len(select_encoder.classes_)+len(required_encoder.classes_)+len(expand_encoder.classes_)])\n",
    "decoded_prediction_expand_select = expand_select_encoder.inverse_transform(user_prompt_prediction[:, len(select_encoder.classes_)+len(required_encoder.classes_)+len(expand_encoder.classes_):len(select_encoder.classes_)+len(required_encoder.classes_)+len(expand_encoder.classes_)+len(expand_select_encoder.classes_)])\n",
    "decoded_prediction_filter = filter_encoder.inverse_transform(user_prompt_prediction[:, len(select_encoder.classes_)+len(required_encoder.classes_)+len(expand_encoder.classes_)+len(expand_select_encoder.classes_):len(select_encoder.classes_)+len(required_encoder.classes_)+len(expand_encoder.classes_)+len(expand_select_encoder.classes_)+len(filter_encoder.classes_)])\n",
    "decoded_prediction_alfred = alfred_encoder.inverse_transform(user_prompt_prediction[:, len(select_encoder.classes_)+len(required_encoder.classes_)+len(expand_encoder.classes_)+len(expand_select_encoder.classes_)+len(filter_encoder.classes_):])\n",
    "\n",
    "\n",
    "# Ausgabe der dekodierten Vorhersagen\n",
    "print(\"Endpoint Prediction:\", decoded_prediction_endpoint[0])\n",
    "print(\"Method Prediction:\", decoded_prediction_method[0])\n",
    "print(\"Presentation Prediction:\", decoded_prediction_presentation[0])\n",
    "print(\"Select Prediction:\", decoded_prediction_select)\n",
    "print(\"Required Prediction:\", decoded_prediction_required)\n",
    "print(\"Expand Prediction:\", decoded_prediction_expand)\n",
    "print(\"Expand Select Prediction:\", decoded_prediction_expand_select)\n",
    "print(\"Filter Prediction:\", decoded_prediction_filter)\n",
    "print(\"Alfred Prediction:\", decoded_prediction_alfred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung in einer JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"endpoint\": \"API_PRODUCTION_ORDER_2_SRV/A_ProductionOrderComponent\",\n",
      "    \"method\": \"GET\",\n",
      "    \"select\": [\n",
      "        \"ManufacturingOrder\"\n",
      "    ],\n",
      "    \"required\": [\n",
      "        \"ManufacturingOrder\"\n",
      "    ],\n",
      "    \"expand\": [\n",
      "        \"to_ProductionOrderComponent\"\n",
      "    ],\n",
      "    \"expand_select\": [\n",
      "        \"BaseUnit\",\n",
      "        \"ManufacturingOrderOperation\",\n",
      "        \"Material\",\n",
      "        \"ProductionPlant\",\n",
      "        \"RequiredQuantity\"\n",
      "    ],\n",
      "    \"filter\": [],\n",
      "    \"presentation\": \"blank\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prediction_results = {\n",
    "    \"endpoint\": decoded_prediction_endpoint[0],\n",
    "    \"method\": decoded_prediction_method[0],\n",
    "    \"select\": decoded_prediction_select[0],\n",
    "    \"required\": decoded_prediction_required[0],\n",
    "    \"expand\": decoded_prediction_expand[0],\n",
    "    \"expand_select\": decoded_prediction_expand_select[0],\n",
    "    \"filter\": decoded_prediction_filter[0],\n",
    "    \"presentation\": decoded_prediction_presentation[0], # wichtig, für die Darstellung im Chatbot; blank = Text, table = Tabelle\n",
    "}\n",
    "\n",
    "json_results = json.dumps(prediction_results, indent=4)\n",
    "\n",
    "# Ausgabe des JSON-Strings\n",
    "print(json_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
